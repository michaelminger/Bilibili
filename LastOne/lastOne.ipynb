{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import time\n",
    "import jieba\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "import re\n",
    "from requests.exceptions import RequestException\n",
    "from wordcloud import WordCloud as wc\n",
    "\n",
    "class getUrl ():\n",
    "    def __init__(self,url):\n",
    "        self.url = url\n",
    "        \n",
    "    def getTxt(self):\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36 Edg/80.0.361.69'        \n",
    "        }\n",
    "        try:\n",
    "            result = requests.get(self.url,headers=self.headers,timeout=30)\n",
    "            result.raise_for_status()\n",
    "            result.encoding = result.apparent_encoding\n",
    "            return result.text\n",
    "        except:\n",
    "            return \"\"    \n",
    "        \n",
    "    def parsePage(self):\n",
    "        res = self.getTxt()\n",
    "        newhtml =etree.HTML(res,etree.HTMLParser())\n",
    "        \n",
    "        result=newhtml.xpath('//*[@id=\"app\"]/div[1]/div/div[1]/div[2]/div[3]/ul/li/div[2]/div[1]/a//@href')\n",
    "\n",
    "        return  result\n",
    "    \n",
    "    \n",
    "class getAvNum():\n",
    "    def __init__(self,url):\n",
    "        self.url = url\n",
    "        \n",
    "    def getTxt(self):\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36 Edg/80.0.361.69'        \n",
    "        }\n",
    "        try:\n",
    "            result = requests.get(self.url,headers=self.headers,timeout=30)\n",
    "            result.raise_for_status()\n",
    "            result.encoding = result.apparent_encoding\n",
    "            return result.text\n",
    "        except:\n",
    "            return \"\"\n",
    "        \n",
    "    def parsePage(self):\n",
    "        res = self.getTxt()\n",
    "        newhtml =etree.HTML(res,etree.HTMLParser())\n",
    "        rlist=newhtml.xpath('/html/head/meta[10]//@content')\n",
    "        \n",
    "        resp = requests.get(rlist[0],headers=self.headers)\n",
    "        match_rule = r'cid=(.*?)&aid'\n",
    "        oid = re.search(match_rule,resp.text).group().replace('cid=','').replace('&aid','')\n",
    "\n",
    "        return  oid\n",
    "    \n",
    "class Bilibili():\n",
    "    \n",
    "    def __init__(self,oid):\n",
    "        self.headers={\n",
    "        'Host': 'api.bilibili.com',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Cache-Control': 'max-age=0',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.92 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Accept-Language': 'zh-CN,zh;q=0.9',\n",
    "        'Cookie': 'finger=edc6ecda; LIVE_BUVID=AUTO1415378023816310; stardustvideo=1; CURRENT_FNVAL=8; buvid3=0D8F3D74-987D-442D-99CF-42BC9A967709149017infoc; rpdid=olwimklsiidoskmqwipww; fts=1537803390'\n",
    "\n",
    "        }\n",
    "        self.url='https://api.bilibili.com/x/v1/dm/list.so?oid='+str(oid)\n",
    "        self.barrage_reault=self.get_page()\n",
    "\n",
    "    def get_page(self):\n",
    "        try:\n",
    "            time.sleep(0.5)\n",
    "            response=requests.get(self.url,headers=self.headers)\n",
    "        except Exception as e:\n",
    "            print('获取xml内容失败,%s' % e)\n",
    "            return False\n",
    "        else:\n",
    "            if response.status_code == 200:\n",
    "                with open('bilibili.xml','wb') as f:\n",
    "                    f.write(response.content)\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "    def param_page(self):\n",
    "        time.sleep(1)\n",
    "        if  self.barrage_reault:\n",
    "            html=etree.parse('bilibili.xml',etree.HTMLParser())\n",
    "            results=html.xpath('//d//text()')\n",
    "            return results\n",
    "\n",
    "def remove_double_barrage(resultlist):\n",
    "    \n",
    "    double_barrage=[]\n",
    "    results=[]\n",
    "    barrage=set()\n",
    "    for result in resultlist:\n",
    "        if result not in results:\n",
    "            results.append(result)\n",
    "        else:\n",
    "            double_barrage.append(result)\n",
    "            barrage.add(result)\n",
    "    return double_barrage,results,barrage\n",
    "\n",
    "def make_wordCould(resultlist):\n",
    "    double_barrages,results,barrages=remove_double_barrage(resultlist)\n",
    "    # 重词计数\n",
    "    with open('barrages.txt','w', -1, 'utf-8', None, None) as f:\n",
    "        for barrage in barrages:\n",
    "            amount=double_barrages.count(barrage)\n",
    "            stt = barrage+':'+str(amount+1)+'\\n'\n",
    "            f.write(stt)\n",
    "                \n",
    "    # 设置停用词\n",
    "    stop_words=['【','】',',','.','?','!','。']\n",
    "    words=[]\n",
    "    if results:\n",
    "        for result in results:\n",
    "            for stop in stop_words:\n",
    "                result=''.join(result.split(stop))\n",
    "            words.append(result)\n",
    "        # 列表拼接成字符串\n",
    "        words=''.join(words)\n",
    "        words=jieba.cut(words)\n",
    "        words=''.join(words)\n",
    "        luo=np.array(Image.open('洛天依.jpg'))    \n",
    "        w=wc(font_path='‪C:/Windows/Fonts/SIMYOU.TTF',background_color='white',width=1600,height=1600,max_words=2000,mask=luo)\n",
    "        w.generate(words)\n",
    "        w.to_file('luo.jpg')\n",
    "            \n",
    "def main():\n",
    "    url=\"https://www.bilibili.com/ranking?spm_id_from=333.851.b_7072696d61727950616765546162.3\"\n",
    "    urls = getUrl(url)\n",
    "    strUrl = urls.parsePage()\n",
    "    ress = []\n",
    "    for i in strUrl:\n",
    "        AV = getAvNum(i)\n",
    "        oid = AV.parsePage()\n",
    "        b=Bilibili(oid)\n",
    "        for j in b.param_page():\n",
    "            ress.append(j)\n",
    "    make_wordCould(ress)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "import time\n",
    "import jieba\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "import re\n",
    "from requests.exceptions import RequestException\n",
    "from wordcloud import WordCloud as wc\n",
    "import csv\n",
    "class getUrl ():\n",
    "    def __init__(self,url):\n",
    "        self.url = url\n",
    "        \n",
    "    def getTxt(self):\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36 Edg/80.0.361.69'        \n",
    "        }\n",
    "        try:\n",
    "            result = requests.get(self.url,headers=self.headers,timeout=30)\n",
    "            result.raise_for_status()\n",
    "            result.encoding = result.apparent_encoding\n",
    "            return result.text\n",
    "        except:\n",
    "            return \"\"    \n",
    "        \n",
    "    def parsePage(self):\n",
    "        res = self.getTxt()\n",
    "        newhtml =etree.HTML(res,etree.HTMLParser())\n",
    "        \n",
    "        result=newhtml.xpath('//*[@id=\"app\"]/div[1]/div/div[1]/div[2]/div[3]/ul/li/div[2]/div[1]/a//@href')\n",
    "\n",
    "        return  result\n",
    "    \n",
    "    \n",
    "class getAvNum():\n",
    "    def __init__(self,url):\n",
    "        self.url = url\n",
    "        \n",
    "    def getTxt(self):\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36 Edg/80.0.361.69'        \n",
    "        }\n",
    "        try:\n",
    "            result = requests.get(self.url,headers=self.headers,timeout=30)\n",
    "            result.raise_for_status()\n",
    "            result.encoding = result.apparent_encoding\n",
    "            return result.text\n",
    "        except:\n",
    "            return \"\"\n",
    "        \n",
    "    def parsePage(self):\n",
    "        res = self.getTxt()\n",
    "        newhtml =etree.HTML(res,etree.HTMLParser())\n",
    "        rlist=newhtml.xpath('//*[@id=\"viewbox_report\"]/div[1]/span[1]/a[1]//text()')\n",
    "        \n",
    "        return  rlist\n",
    "    \n",
    "class Bilibili():\n",
    "    \n",
    "    def __init__(self,oid):\n",
    "        self.headers={\n",
    "        'Host': 'api.bilibili.com',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Cache-Control': 'max-age=0',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.92 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Accept-Language': 'zh-CN,zh;q=0.9',\n",
    "        'Cookie': 'finger=edc6ecda; LIVE_BUVID=AUTO1415378023816310; stardustvideo=1; CURRENT_FNVAL=8; buvid3=0D8F3D74-987D-442D-99CF-42BC9A967709149017infoc; rpdid=olwimklsiidoskmqwipww; fts=1537803390'\n",
    "\n",
    "        }\n",
    "        self.url='https://api.bilibili.com/x/v1/dm/list.so?oid='+str(oid)\n",
    "        self.barrage_reault=self.get_page()\n",
    "\n",
    "    def get_page(self):\n",
    "        try:\n",
    "            time.sleep(0.5)\n",
    "            response=requests.get(self.url,headers=self.headers)\n",
    "        except Exception as e:\n",
    "            print('获取xml内容失败,%s' % e)\n",
    "            return False\n",
    "        else:\n",
    "            if response.status_code == 200:\n",
    "                with open('bilibili.xml','wb') as f:\n",
    "                    f.write(response.content)\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "    def param_page(self):\n",
    "        time.sleep(1)\n",
    "        if  self.barrage_reault:\n",
    "            html=etree.parse('bilibili.xml',etree.HTMLParser())\n",
    "            results=html.xpath('//d//text()')\n",
    "            return results\n",
    "\n",
    "def remove_double_barrage(resultlist):\n",
    "    \n",
    "    double_barrage=[]\n",
    "    results=[]\n",
    "    barrage=set()\n",
    "    for result in resultlist:\n",
    "        if result not in results:\n",
    "            results.append(result)\n",
    "        else:\n",
    "            double_barrage.append(result)\n",
    "            barrage.add(result)\n",
    "    return double_barrage,results,barrage\n",
    "\n",
    "def make_wordCould(resultlist):\n",
    "    double_barrages,results,barrages=remove_double_barrage(resultlist)\n",
    "    with open('barrages.txt','w', -1, 'utf-8', None, None) as f:\n",
    "        for barrage in barrages:\n",
    "            amount=double_barrages.count(barrage)\n",
    "            stt = barrage+':'+str(amount+1)+'\\n'\n",
    "            f.write(stt)\n",
    "                \n",
    "    stop_words=['【','】',',','.','?','!','。']\n",
    "    words=[]\n",
    "    if results:\n",
    "        for result in results:\n",
    "            for stop in stop_words:\n",
    "                result=''.join(result.split(stop))\n",
    "            words.append(result)\n",
    "        # 列表拼接成字符串\n",
    "        words=''.join(words)\n",
    "        words=jieba.cut(words)\n",
    "        words=''.join(words)\n",
    "        luo=np.array(Image.open('洛天依.jpg'))    \n",
    "        w=wc(font_path='‪C:/Windows/Fonts/SIMYOU.TTF',background_color='white',width=1600,height=1600,max_words=2000,mask=luo)\n",
    "        w.generate(words)\n",
    "        w.to_file('luo.jpg')\n",
    "        \n",
    "def csvdata(data):\n",
    "    with open('top20.csv','w',encoding = 'utf-8',newline='')as csvfile:\n",
    "        fieldnames = ['分类']\n",
    "        writer = csv.DictWriter(csvfile,fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for i in data:\n",
    "            writer.writerow({'分类':i[0]})\n",
    "        print('ok')           \n",
    "        \n",
    "def main():\n",
    "    url=\"https://www.bilibili.com/ranking?spm_id_from=333.851.b_7072696d61727950616765546162.3\"\n",
    "    urls = getUrl(url)\n",
    "    strUrl = urls.parsePage()\n",
    "    ress = []\n",
    "    for i in strUrl:\n",
    "        AV = getAvNum(i)\n",
    "        oid = AV.parsePage()\n",
    "        ress.append(oid)\n",
    "    csvdata(ress)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
